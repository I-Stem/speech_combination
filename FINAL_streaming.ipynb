{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AZURE STREAMING CUSTOM TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import time\n",
    "def rec(obj1):\n",
    "    \n",
    "    config = speechsdk.SpeechConfig(subscription=\"8c9e3cd4eec741e5b117700fd9e1e278\", region=\"westus\")\n",
    "    config.endpoint_id = \"be64b446-598f-4862-af64-d74968fafaed\"\n",
    "    speech_recognizer= speechsdk.SpeechRecognizer(speech_config=config)\n",
    "    evt=None\n",
    "\n",
    "    done = False\n",
    "\n",
    "    def stop_cb(evt):\n",
    "        \"\"\"callback that stops continuous recognition upon receiving an event `evt`\"\"\"\n",
    "#         print('CLOSING ')\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    def attach(evt):\n",
    "        obj1.append(evt)\n",
    "        if re.search(r'\\b(exit|quit)\\b', ((evt.result).text), re.I):\n",
    "            print('azure Exiting..')\n",
    "            speech_recognizer.stop_continuous_recognition()\n",
    "            nonlocal done\n",
    "            done = True\n",
    "            #intermediate results\n",
    "#         print((evt.result).text)\n",
    "            \n",
    "    print('azure')\n",
    "    speech_recognizer.recognized.connect(lambda evt: attach(evt))\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        time.sleep(.5)\n",
    "\n",
    "        \n",
    "def azure(crap):\n",
    "    obj1 = []\n",
    "    rec(obj1)\n",
    "    st=''\n",
    "    for i in obj1:\n",
    "        st=st+' '+((i.result).text)\n",
    "    st=(st.rsplit(' ', 1)[0])\n",
    "    return st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCP ENHANCED MODEL WITH CUSTOM CAPABILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "import pyaudio\n",
    "from six.moves import queue\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "\n",
    "\n",
    "class MicrophoneStream(object):\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "    def __init__(self, rate, chunk):\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1, rate=self._rate,\n",
    "            input=True, frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b''.join(data)\n",
    "\n",
    "\n",
    "def listen_print_loop(responses):\n",
    "    \"\"\"Iterates through server responses and prints them.\n",
    "\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "\n",
    "    Each response may contain multiple results, and each result may contain\n",
    "    multiple alternatives; for details, see https://goo.gl/tjCPAU.  Here we\n",
    "    print only the transcription for the top alternative of the top result.\n",
    "\n",
    "    In this case, responses are provided for interim results as well. If the\n",
    "    response is an interim one, print a line feed at the end of it, to allow\n",
    "    the next result to overwrite it, until the response is a final one. For the\n",
    "    final one, print a newline to preserve the finalized transcription.\n",
    "    \"\"\"\n",
    "    st=''\n",
    "    num_chars_printed = 0\n",
    "    for response in responses:\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        # The `results` list is consecutive. For streaming, we only care about\n",
    "        # the first result being considered, since once it's `is_final`, it\n",
    "        # moves on to considering the next utterance.\n",
    "        result = response.results[0]\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "        \n",
    "        # Display the transcription of the top alternative.\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        # Display interim results, but with a carriage return at the end of the\n",
    "        # line, so subsequent lines will overwrite them.\n",
    "        #\n",
    "        # If the previous result was longer than this one, we need to print\n",
    "        # some extra spaces to overwrite the previous result\n",
    "        overwrite_chars = ' ' * (num_chars_printed - len(transcript))\n",
    "\n",
    "        if result.is_final:\n",
    "            st=st+' '+transcript \n",
    "            # Exit recognition if any of the transcribed phrases could be\n",
    "            # one of our keywords.\n",
    "            if re.search(r'\\b(exit|quit)\\b', transcript, re.I):\n",
    "                print('google Exiting..')\n",
    "                num_chars_printed = 0\n",
    "                return st\n",
    "            \n",
    "\n",
    "def gcp(cra):\n",
    "    print('google')\n",
    "    language_code = 'en-US'  # a BCP-47 language tag\n",
    "    client = speech.SpeechClient()\n",
    "    \n",
    "    phrase = \"the indusvalley civilization was situated on the banks of\"\n",
    "    \n",
    "    speech_contexts_element = {\"phrases\": phrase}\n",
    "    speech_context = [speech_contexts_element]\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code,\n",
    "        use_enhanced = True,\n",
    "        model='video',\n",
    "        speech_contexts= speech_context)    \n",
    "    \n",
    "    streaming_config = types.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        interim_results=True)\n",
    "    text=''\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (types.StreamingRecognizeRequest(audio_content=content)\n",
    "                    for content in audio_generator)\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        # Now, put the transcription responses to use.\n",
    "        text=text+' '+listen_print_loop(responses)\n",
    "    return text.rsplit(' ', 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUNNING BOTH API's TOGETHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google\n",
      "azure\n",
      "azure Exiting..\n",
      "google Exiting..\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "from threading import Thread\n",
    "\n",
    "que = queue.Queue()\n",
    "t1 = Thread(target=lambda q, arg1: q.put(gcp(arg1)), args=(que,10))\n",
    "t2 = Thread(target=lambda q, arg2: q.put(azure(arg2)), args=(que,10))\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "ag=[]\n",
    "while not que.empty():\n",
    "    result = que.get()\n",
    "    ag.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure  The Indus Valley civilization was ancient civilization situated on the banks of River in this\n",
      "gcp   the Indus Valley Civilization ancient civilization situated on the banks of this\n"
     ]
    }
   ],
   "source": [
    "print('azure',ag[0])\n",
    "print('gcp',ag[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
